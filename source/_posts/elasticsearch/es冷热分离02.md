---
title: es7实现数据自动冷热分离02
date: 2021-12-16 09:42
categories:
- elasticsearch
tags:
- es
---
  
  
摘要: es7 实现数据自动冷热分离02
<!-- more -->


用 Elasticsearch 来索引日志事件等基于时间的数据的人可能已经习惯了"每日一索引" 模式

    使用以天为粒度的索引名字来存放当天的日志数据，一天过去后再建一个新索引。新索引的属性可以由索引模板来提前控制。

这种模式很容易理解并且易于实现，但是它掩盖了索引管理复杂的细节：

    为了达到较高的写入速度，活跃索引分片需要分布在尽可能多的节点上。
    为了提高搜索速度和降低资源消耗，分片数量需要尽可能地少，但是也不能有过大的单个分片进而不便操作
    一天一个索引确实易于清理陈旧数据，但是一天到底需要多少个分片呢？
    每天的写入压力是一成不变的吗？还是一天分片过多，而下一天分片不够用呢？

在这篇文章中我将介绍新的”滚动模式“和用来实现它的 API 们，这个模式可以更加简单且高效地管理基于时间的索引。




## 滚动模式
滚动模式工作流程如下：

    有一个用于写入的索引别名，其指向活跃索引
    另外一个用于读取（搜索）的索引别名，指向不活跃索引
    活跃索引具有和热节点数量一样多的分片，可以充分发挥昂贵硬件的索引写入能力
    当活跃索引太满或者太老的时候，它就会滚动：新建一个索引并且索引别名自动从老索引切换到新索引
    移动老索引到冷节点上并且缩小为一个分片，之后可以强制合并和压缩。
  

## 入门
假设我们有一个具有 10 个热节点和一个冷节点池的集群。理想情况下我们的活跃索引（接收所有写入的索引）应该在每个热节点上均匀分布一个分片，以此来尽可能地在多个机器上分散写入压力。

我们让每个主分片都有一个复制分片来允许一个节点失效而不丢失数据。这意味着我们的活跃索引应该有 5 个主分片，加起来一共 10 个分片（每个节点一个）。我们也可以用 10 个主分片（包含冗余一共 20 个分片），这样每个节点两个分片。

首先，为活跃索引创建一个索引模版:
```
PUT _template/active-logs
{
  "template": "active-logs-*",
  "settings": {
    "number_of_shards": 5,
    "number_of_replicas": 1,
    "routing.allocation.include.box_type": "hot",
    "routing.allocation.total_shards_per_node": 2
  },
  "aliases": {
    "active-logs": {}, 
    "search-logs": {}
  }
}
```

由这个模板创建的索引会被分配到标记为 `box_type:hot `的节点上，而 `total_shards_per_node` 配置会保证将分片均匀分布在热节点中。我把其设置为 2 而不是 1，这样当一个节点失效时也可以继续分配分片。


我们将会用 `active-logs` 别名来写入当前的活跃索引，用 `search-logs` 别名来查询所有的日志索引。
下面是非活跃索引的模板:
```
PUT _template/inactive-logs
{
  "template": "inactive-logs-*", 
  "settings": { 
    "number_of_shards": 1, 
    "number_of_replicas": 0,
    "routing.allocation.include.box_type": "cold",
    "codec": "best_compression"
  }
}
```
归档的索引应该被分配到冷节点上并且使用 `deflate` 压缩来节约磁盘空间。我会在之后解释为什么把 `replicas`设置为 0。


现在可以创建第一个活跃索引了:
```
PUT active-logs-1
```
Rollover API 会将名字中的-1 识别为一个计数器。


索引日志事件
当创建`active-logs-1` 索引时，我们也创建了 `active-logs` 别名。在此之后，我们应该仅使用别名来写入，文档会被发送到当前的活动索引:

```
POST active-logs/log/_bulk
{ "create": {}} { "text": "Some log message", "@timestamp": "2016-07-01T01:00:00Z" }
{ "create": {}} { "text": "Some log message", "@timestamp": "2016-07-02T01:00:00Z" }
{ "create": {}} { "text": "Some log message", "@timestamp": "2016-07-03T01:00:00Z" }
{ "create": {}} { "text": "Some log message", "@timestamp": "2016-07-04T01:00:00Z" }
{ "create": {}} { "text": "Some log message", "@timestamp": "2016-07-05T01:00:00Z" }
```

### 滚动索引
在某个时间点，活跃索引变得过大或者过老，这时你想用一个新的空索引来替换它。Rollover API 允许你指定触发滚动操作的具体大小或者时间限制。

多大才是过大？一如以往，看情况。这取决于你的硬件性能，你的搜索操作的类型，你想要达到的性能效果和你能接受的分片恢复时间等等。可以从例如 1 亿或者 10 亿这种数字开始，依据搜索性能、数据保留时间和可用磁盘空间来上下调整。

一个分片能包含的文档数有一个硬限制：2147483519。如果你打算把活跃索引缩小到一个分片，那么活跃索引中的文档数不能超过 21 亿。如果活跃索引中的文档一个分片放不下，你可以将活跃索引缩小到多个分片，只要目标分片数是原来分片数的因子，例如 6 到 3 或者 6 到 2。

基于时间来滚动索引很方便，因为可以按照小时、天或者星期来整理索引。但其实按照索引中的文档数来滚动索引更加高效。按照数量来滚动的优点之一就是所有的分片会具有大致相同的大小，这样做负载均衡更加方便。

可以用定时任务来定期调用 rollover API 去检查是否到达了 max_docs 或者 max_age 限制。当超过某个限制时，索引就会被滚动。因为我们在例子中只索引了 5 个文档，我们将 max_docs 值设置为 5，并且（为了完整性）将 max_age 设置为一周：

```
POST active-logs/_rollover
{
  "conditions": {
    "max_age": "7d",
    "max_docs": 5
  }
}
```

这个请求告诉 Elasticsearch 去滚动 active-logs 别名指向的索引，如果这个索引至少在七天之前创建或者至少包含 5 个文档。应答如下：
```
{
  "old_index": "active-logs-1",
  "new_index": "active-logs-2",
  "rolled_over": true,
  "dry_run": false,
  "conditions": {
    "[max_docs: 5]": true,
    "[max_age: 7d]": false
  }
}
```

因为满足了 max_docs: 5 条件，active-logs-1 索引被滚动到 active-logs-2 索引。这意味着一个叫做 active-logs-2 的索引被创建（基于 active-logs 模板），并且 active-logs 别名从 active-logs-1 切换到 active-logs-2。


